{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc627c28",
   "metadata": {},
   "source": [
    "# AutoGen Examples: Building Conversational AI Agent Systems\n",
    "\n",
    "This notebook provides hands-on examples of using Microsoft's AutoGen framework for building conversational AI agent systems. You can run these examples to gain practical experience with this innovative framework.\n",
    "\n",
    "## Helpful Resources\n",
    "\n",
    "- [Official AutoGen Documentation](https://microsoft.github.io/autogen/)\n",
    "- [AutoGen GitHub Repository](https://github.com/microsoft/autogen)\n",
    "- [AutoGen Examples Gallery](https://microsoft.github.io/autogen/docs/Examples)\n",
    "- [AutoGen Discord Community](https://discord.gg/pAbnFJrkgZ)\n",
    "- [AutoGen API Reference](https://microsoft.github.io/autogen/docs/reference/)\n",
    "- [AutoGen Research Paper](https://arxiv.org/abs/2308.08155)\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "First, let's install the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pyautogen\n",
    "\n",
    "# For comprehensive installation with all features\n",
    "# !pip install \"pyautogen[all]\"\n",
    "\n",
    "# For Azure OpenAI support (already included in base package)\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31459b",
   "metadata": {},
   "source": [
    "## Setting API Keys and Configurations\n",
    "\n",
    "For these examples to work, you'll need to set your API keys for OpenAI or Azure OpenAI. Replace the placeholders with your actual API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a968954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "\n",
    "# Option 1: OpenAI Setup\n",
    "# Set your OpenAI API key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Replace with your actual API key\n",
    "\n",
    "# OpenAI configuration\n",
    "openai_config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': os.environ[\"OPENAI_API_KEY\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Option 2: Azure OpenAI Setup\n",
    "# Set your Azure OpenAI variables\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-azure-openai-api-key\"  # Replace with your actual Azure API key\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://your-resource-name.openai.azure.com/\"  # Replace with your endpoint\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',  # The deployment name you chose when you deployed the GPT-4 model\n",
    "        'api_key': os.environ.get(\"AZURE_OPENAI_API_KEY\", \"\"),\n",
    "        'api_type': 'azure',\n",
    "        'api_base': os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        'api_version': '2023-05-15'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Select which configuration to use (OpenAI or Azure OpenAI)\n",
    "config_list = openai_config_list  # Change to azure_openai_config_list to use Azure\n",
    "\n",
    "# Alternatively, you can load from a configuration file\n",
    "# config_list = autogen.config_list_from_json(\"OAI_CONFIG_LIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09d847",
   "metadata": {},
   "source": [
    "## Example 1: Basic Two-Agent Conversation\n",
    "\n",
    "Let's start with a simple conversation between two agents: an AI assistant and a user proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c365bd2",
   "metadata": {},
   "source": [
    "## Using Azure OpenAI with AutoGen\n",
    "\n",
    "Here's how to explicitly configure and use Azure OpenAI with AutoGen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9acbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "from typing import Literal\n",
    "\n",
    "# Define Azure OpenAI configuration (uncomment and fill in your actual values)\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-azure-openai-api-key\"\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://your-resource-name.openai.azure.com/\"\n",
    "\n",
    "# Configure for Azure OpenAI\n",
    "azure_config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",  # This should be the deployment name you chose\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": \"2023-05-15\",\n",
    "        \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\", \"\"),\n",
    "        \"api_base\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "# Azure OpenAI-specific settings\n",
    "azure_llm_config = {\n",
    "    \"config_list\": azure_config_list,\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "# Create agents with Azure OpenAI\n",
    "assistant_with_azure = autogen.AssistantAgent(\n",
    "    name=\"Azure_Assistant\",\n",
    "    llm_config=azure_llm_config,\n",
    "    system_message=\"You are a helpful AI assistant powered by Azure OpenAI. Respond concisely.\"\n",
    ")\n",
    "\n",
    "user_proxy_with_azure = autogen.UserProxyAgent(\n",
    "    name=\"User_With_Azure\",\n",
    "    human_input_mode=\"NEVER\",  # Don't ask for human input in this example\n",
    "    max_consecutive_auto_reply=5,\n",
    "    code_execution_config={\"work_dir\": \"coding_azure\", \"use_docker\": False},\n",
    "    system_message=\"You are a proxy for the user testing Azure OpenAI integration.\"\n",
    ")\n",
    "\n",
    "# To run this conversation (uncomment when you've configured Azure OpenAI)\n",
    "'''\n",
    "user_proxy_with_azure.initiate_chat(\n",
    "    assistant_with_azure,\n",
    "    message=\"Can you write a Python function that generates a Fibonacci sequence up to n terms?\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# Create an assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"AI_Assistant\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a helpful AI assistant. Respond concisely and clearly.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent that doesn't require human input\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User_Proxy\",\n",
    "    human_input_mode=\"NEVER\",  # Don't ask for human input in this example\n",
    "    max_consecutive_auto_reply=5,  # Limit the conversation length\n",
    "    system_message=\"You are a proxy for the user. Ask the AI assistant questions about AI frameworks.\"\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What are the key differences between LangChain and AutoGen frameworks?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d59cc",
   "metadata": {},
   "source": [
    "## Example 2: Agent with Code Execution\n",
    "\n",
    "One of AutoGen's strengths is its ability to generate and execute code. Let's create an agent that can write and run Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "import os\n",
    "\n",
    "# Ensure we have a coding workspace\n",
    "os.makedirs(\"coding_workspace\", exist_ok=True)\n",
    "\n",
    "# Create an assistant agent focused on coding\n",
    "coding_assistant = AssistantAgent(\n",
    "    name=\"Coding_Assistant\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a Python expert who writes efficient, well-documented code. When asked to code, provide complete and executable solutions.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent with code execution capabilities\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"TERMINATE\",  # Only ask for human input when termination is requested\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding_workspace\",\n",
    "        \"use_docker\": False  # Set to True to use Docker for isolation\n",
    "    }\n",
    ")\n",
    "\n",
    "# Start the conversation with a coding task\n",
    "user_proxy.initiate_chat(\n",
    "    coding_assistant,\n",
    "    message=\"Write a Python script that creates a web server to display 'Hello, World!' when accessed.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2d5b2",
   "metadata": {},
   "source": [
    "## Example 3: Multi-Agent Group Chat\n",
    "\n",
    "AutoGen excels at facilitating conversations between multiple specialized agents. Let's create a group chat with several agents that collaborate on a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# Create specialized agents for different roles\n",
    "programmer = AssistantAgent(\n",
    "    name=\"Programmer\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are an expert programmer specializing in Python. You write clean, efficient, and well-documented code.\"\n",
    ")\n",
    "\n",
    "data_scientist = AssistantAgent(\n",
    "    name=\"Data_Scientist\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a data scientist who excels at data analysis, visualization, and machine learning.\"\n",
    ")\n",
    "\n",
    "product_manager = AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a product manager who focuses on user needs and ensuring that technical solutions solve real problems effectively.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"TERMINATE\",  # Only ask for human input when termination is requested\n",
    "    code_execution_config={\"work_dir\": \"coding_workspace\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Create a group chat with all agents\n",
    "groupchat = GroupChat(\n",
    "    agents=[user_proxy, programmer, data_scientist, product_manager],\n",
    "    messages=[],\n",
    "    max_round=12\n",
    ")\n",
    "\n",
    "# Create a manager for the group chat\n",
    "manager = GroupChatManager(groupchat=groupchat)\n",
    "\n",
    "# Start the conversation with a complex problem that requires collaboration\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"We need to build a dashboard that visualizes Twitter sentiment about AI technologies. Please work together to create a plan and some sample code.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb174e1",
   "metadata": {},
   "source": [
    "## Example 4: Human-in-the-Loop Interaction\n",
    "\n",
    "AutoGen allows for human feedback during agent conversations. Let's create an example where human input is requested at specific points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# Create an assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"AI_Assistant\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are an AI assistant helping a user build a data analysis project. Ask clarifying questions when needed.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent that requests human input at key decision points\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"ALWAYS\",  # Always ask for human input when the agent is prompted\n",
    "    code_execution_config={\"work_dir\": \"coding_workspace\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"I want to build a data visualization project showing climate change trends over time.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52390841",
   "metadata": {},
   "source": [
    "## Example 5: Custom Function Calling\n",
    "\n",
    "Let's implement a scenario where agents can use custom functions to perform specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "import json\n",
    "\n",
    "# Define custom functions that agents can use\n",
    "def search_database(query):\n",
    "    \"\"\"Simulated database search function\"\"\"\n",
    "    # In a real scenario, this would connect to a database\n",
    "    mock_database = {\n",
    "        \"AI frameworks\": [\"LangChain\", \"AutoGen\", \"CrewAI\", \"LangGraph\"],\n",
    "        \"Programming languages\": [\"Python\", \"JavaScript\", \"Rust\", \"Go\"],\n",
    "        \"Cloud providers\": [\"AWS\", \"Azure\", \"Google Cloud\", \"IBM Cloud\"]\n",
    "    }\n",
    "    \n",
    "    for category, items in mock_database.items():\n",
    "        if query.lower() in category.lower():\n",
    "            return json.dumps({\"category\": category, \"items\": items})\n",
    "    \n",
    "    return json.dumps({\"error\": \"No results found\", \"query\": query})\n",
    "\n",
    "def calculate_statistics(data_string):\n",
    "    \"\"\"Calculate basic statistics on a list of numbers\"\"\"\n",
    "    try:\n",
    "        # Convert the input string to a list of numbers\n",
    "        data = [float(x) for x in data_string.split(',')]\n",
    "        result = {\n",
    "            \"count\": len(data),\n",
    "            \"mean\": sum(data) / len(data) if data else 0,\n",
    "            \"min\": min(data) if data else None,\n",
    "            \"max\": max(data) if data else None\n",
    "        }\n",
    "        return json.dumps(result)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "# Create the assistant agent\n",
    "function_assistant = AssistantAgent(\n",
    "    name=\"Function_Assistant\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are an AI assistant with access to special functions. You can search a database with search_database(query) and calculate statistics with calculate_statistics(data_string).\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent with registered functions\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    function_map={\n",
    "        \"search_database\": search_database,\n",
    "        \"calculate_statistics\": calculate_statistics\n",
    "    }\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "user_proxy.initiate_chat(\n",
    "    function_assistant,\n",
    "    message=\"What AI frameworks are available in the database? Also, can you calculate statistics for this data: 10, 15, 20, 25, 30?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e2ee0",
   "metadata": {},
   "source": [
    "## Example 6: Iterative Task Solving with ReAct\n",
    "\n",
    "AutoGen can implement the ReAct (Reasoning + Acting) pattern for iterative task solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# Create an assistant agent with ReAct-like capabilities\n",
    "react_assistant = AssistantAgent(\n",
    "    name=\"ReAct_Assistant\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0,  # Lower temperature for more deterministic reasoning\n",
    "    },\n",
    "    system_message=\"\"\"You are an assistant that carefully solves tasks step by step.\n",
    "For complex problems:\n",
    "1. Break down the problem into smaller steps\n",
    "2. Reason through each step individually\n",
    "3. Verify your reasoning before providing the final answer\n",
    "If you need to write code, make it executable and test it thoroughly.\n",
    "Always show your full reasoning process.\"\"\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent with code execution\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    code_execution_config={\"work_dir\": \"coding_workspace\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Start the conversation with a complex problem\n",
    "user_proxy.initiate_chat(\n",
    "    react_assistant,\n",
    "    message=\"Solve this programming challenge: Write a function that finds all prime numbers up to n using the Sieve of Eratosthenes algorithm. Then use it to count how many prime numbers are there between 1 and 1000.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2709770",
   "metadata": {},
   "source": [
    "## Further Exploration\n",
    "\n",
    "These examples demonstrate the core capabilities of AutoGen. For more advanced usage, consider exploring:\n",
    "\n",
    "1. **Advanced Agent Customization**: Creating agents with specialized behaviors and reasoning patterns\n",
    "2. **More Complex Group Chat Dynamics**: Implementing multi-stage conversations with different agent participation\n",
    "3. **Memory Management**: Techniques for maintaining long-term memory across conversations\n",
    "4. **Docker Integration**: Secure code execution in isolated environments\n",
    "5. **Integration with External Services**: Connecting agents to APIs and databases\n",
    "\n",
    "Check out the [AutoGen documentation](https://microsoft.github.io/autogen/) for more examples and advanced usage scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdcf57",
   "metadata": {},
   "source": [
    "## Complete Example with Configuration Choice\n",
    "\n",
    "This example shows how to create a multi-agent system where you can easily switch between OpenAI and Azure OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable Multi-Agent Example\n",
    "\n",
    "# Function to create config based on provider choice\n",
    "def get_llm_config(provider=\"openai\"):\n",
    "    if provider == \"azure\":\n",
    "        # Azure OpenAI configuration\n",
    "        return {\n",
    "            \"config_list\": [\n",
    "                {\n",
    "                    \"model\": \"gpt-4\",  # Your deployment name\n",
    "                    \"api_type\": \"azure\",\n",
    "                    \"api_version\": \"2023-05-15\",\n",
    "                    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\", \"\"),\n",
    "                    \"api_base\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    else:  # Default to OpenAI\n",
    "        # OpenAI configuration\n",
    "        return {\n",
    "            \"config_list\": [\n",
    "                {\n",
    "                    \"model\": \"gpt-4\",\n",
    "                    \"api_key\": os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "\n",
    "# Choose your provider here\n",
    "provider = \"openai\"  # Change to \"azure\" to use Azure OpenAI\n",
    "\n",
    "# Get appropriate config\n",
    "llm_config = get_llm_config(provider)\n",
    "\n",
    "# Create a coding agent\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a Python expert. Write efficient, well-documented code based on requirements.\"\n",
    ")\n",
    "\n",
    "# Create a code reviewer agent\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"Reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a code reviewer who focuses on code quality, security, and best practices.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent with code execution capability\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"coding_workspace\", \"use_docker\": False},\n",
    "    system_message=\"You represent the user in this conversation.\"\n",
    ")\n",
    "\n",
    "# Create a group chat\n",
    "from autogen.agentchat.groupchat import GroupChat\n",
    "from autogen.agentchat.agent import Agent\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "def select_speaker(groupchat: GroupChat, messages: List[Dict]):\n",
    "    \"\"\"Function to select the next speaker in the group chat.\"\"\"\n",
    "    # Extract last message's content and speaker\n",
    "    last_message = messages[-1]\n",
    "    last_speaker = last_message[\"sender\"]\n",
    "    content = last_message[\"content\"]\n",
    "    \n",
    "    # Default to user_proxy for final decisions or when input is needed\n",
    "    if \"should we implement this?\" in content.lower() or \"what do you think?\" in content.lower():\n",
    "        return user_proxy\n",
    "    \n",
    "    # If the last message was from the user, default to coder\n",
    "    if last_speaker == user_proxy.name:\n",
    "        return coder\n",
    "    \n",
    "    # If the message contains code and was from coder, let reviewer speak\n",
    "    if \"```\" in content and last_speaker == coder.name:\n",
    "        return reviewer\n",
    "    \n",
    "    # If reviewer just gave feedback, let coder implement changes\n",
    "    if last_speaker == reviewer.name:\n",
    "        return coder\n",
    "    \n",
    "    # Default back to reviewer for another round of feedback\n",
    "    return reviewer\n",
    "\n",
    "# Set up the group chat\n",
    "groupchat = GroupChat(\n",
    "    agents=[user_proxy, coder, reviewer],\n",
    "    messages=[],\n",
    "    max_round=12,\n",
    "    speaker_selection_method=select_speaker\n",
    ")\n",
    "\n",
    "# Create a manager for the group chat\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat)\n",
    "\n",
    "# Start the conversation (uncomment to run)\n",
    "'''\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Create a Python script that analyzes a CSV file containing sales data and generates a bar chart of monthly revenue.\"\n",
    ")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
